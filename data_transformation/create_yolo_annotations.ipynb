{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unique_grayscale_values(masks_folder):\n",
    "    \"\"\"Utility to print unique grayscale values from a mask dataset\"\"\"\n",
    "    unique_values = set()\n",
    "    \n",
    "    for mask_file in os.listdir(masks_folder):\n",
    "        if mask_file.endswith(\".png\"):\n",
    "            mask_path = os.path.join(masks_folder, mask_file)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            unique_values.update(np.unique(mask))\n",
    "    \n",
    "    print(\"Unique grayscale values found:\", sorted(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique grayscale values found: [0, 64, 128, 191, 255]\n"
     ]
    }
   ],
   "source": [
    "mask_folder = \"path/to/your/training_masks\"\n",
    "find_unique_grayscale_values(mask_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_annotations(images_folder, masks_folder, output_folder, grayscale_to_class, images_output_folder):\n",
    "    \"\"\"Convert grayscale segmentation masks to YOLO-format bounding boxes\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    os.makedirs(images_output_folder, exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(images_folder) if f.endswith(\".png\")]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(images_folder, image_file)\n",
    "        mask_path = os.path.join(masks_folder, image_file)\n",
    "        \n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"Mask not found for {image_file}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Copy image to new folder\n",
    "        shutil.copy(image_path, os.path.join(images_output_folder, image_file))\n",
    "        \n",
    "        # Read mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        h, w = mask.shape\n",
    "        \n",
    "        # Find unique grayscale values (excluding 0, which is the background)\n",
    "        unique_values = np.unique(mask)\n",
    "        unique_values = unique_values[unique_values > 0]\n",
    "        \n",
    "        annotations = []\n",
    "        for value in unique_values:\n",
    "            if value not in grayscale_to_class:\n",
    "                continue\n",
    "            class_id = grayscale_to_class[value]\n",
    "            \n",
    "            # Create a binary mask for the current object\n",
    "            obj_mask = (mask == value).astype(np.uint8) * 255\n",
    "            \n",
    "            # Find contours\n",
    "            contours, _ = cv2.findContours(obj_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            for contour in contours:\n",
    "                x, y, width, height = cv2.boundingRect(contour)\n",
    "                \n",
    "                # Convert to YOLO format\n",
    "                x_center = (x + width / 2) / w\n",
    "                y_center = (y + height / 2) / h\n",
    "                norm_width = width / w\n",
    "                norm_height = height / h\n",
    "                \n",
    "                annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\")\n",
    "        \n",
    "        # Save annotation file\n",
    "        annotation_path = os.path.join(output_folder, image_file.replace(\".png\", \".txt\"))\n",
    "        with open(annotation_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "train_images = \"path/to/training_images\"\n",
    "train_masks = \"path/to/training_masks\"\n",
    "train_labels_output = \"path/to/output/labels/train\"\n",
    "train_images_output = \"path/to/output/images/train\"\n",
    "\n",
    "val_images = \"path/to/validation_images\"\n",
    "val_masks = \"path/to/validation_masks\"\n",
    "val_labels_output = \"path/to/output/labels/val\"\n",
    "val_images_output = \"path/to/output/images/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grayscale-to-class mapping \n",
    "grayscale_to_class = {\n",
    "    64: 0,   # Class 0\n",
    "    128: 1,  # Class 1\n",
    "    191: 2,  # Class 2\n",
    "    255: 3   # Class 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 45/45 [00:00<00:00, 79.53it/s]\n",
      "Processing images: 100%|██████████| 11/11 [00:00<00:00, 97.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run annotation creation\n",
    "create_yolo_annotations(train_images, train_masks, train_labels_output, grayscale_to_class, train_images_output)\n",
    "create_yolo_annotations(val_images, val_masks, val_labels_output, grayscale_to_class, val_images_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the YOLO bounding boxes \n",
    "It is a good way to verify if your annotation logic is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visualized image to: /home/usuaris/imatge/sara.alonso.del.hoyo/TFG_BAL/data/Dataset_Alejandro/debug/Tile1_with_boxes.png\n"
     ]
    }
   ],
   "source": [
    "def visualize_yolo_annotations(image_path, annotation_path, output_path):\n",
    "    \"\"\"Visualize YOLO bounding boxes over the original image\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not load image:\", image_path)\n",
    "        return\n",
    "    \n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    if not os.path.exists(annotation_path):\n",
    "        print(\"Annotation file not found:\", annotation_path)\n",
    "        return\n",
    "\n",
    "    with open(annotation_path, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "        \n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            continue\n",
    "\n",
    "        class_id, x_center, y_center, box_width, box_height = map(float, parts)\n",
    "\n",
    "        # Convert from YOLO format to pixel coordinates\n",
    "        x_center *= w\n",
    "        y_center *= h\n",
    "        box_width *= w\n",
    "        box_height *= h\n",
    "\n",
    "        x1 = int(x_center - box_width / 2)\n",
    "        y1 = int(y_center - box_height / 2)\n",
    "        x2 = int(x_center + box_width / 2)\n",
    "        y2 = int(y_center + box_height / 2)\n",
    "\n",
    "        # Draw rectangle and class label\n",
    "        color = (0, 255, 0)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image, f\"Class {int(class_id)}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Saved visualized image to: {output_path}\")\n",
    "\n",
    "# Visualize a YOLO annotation\n",
    "image_path = \"path/to/output/images/train/Tile1.png\"\n",
    "annotation_path = \"path/to/output/labels/train/Tile1.txt\"\n",
    "output_path = \"path/to/visual_output/Tile1_with_boxes.png\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "visualize_yolo_annotations(image_path, annotation_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bal-venv",
   "language": "python",
   "name": "bal-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
